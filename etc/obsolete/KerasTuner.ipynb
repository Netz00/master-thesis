{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tuner test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/129.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/guides/keras_tuner/getting_started/\n",
    "\n",
    "https://keras.io/guides/keras_tuner/visualize_tuning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model_name = hp.Choice('Model', ['VGG19','EfficientNetV2B0','MobileNetV2'])\n",
    "\n",
    "    if model_name == 'VGG19':\n",
    "      base_model = keras.applications.VGG19(\n",
    "          weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "          input_shape=(image_size[0], image_size[1], 3),\n",
    "          include_top=False,\n",
    "      )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    elif model_name == 'EfficientNetV2B0':\n",
    "      base_model = keras.applications.EfficientNetV2B0(\n",
    "          weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "          input_shape=(image_size[0], image_size[1], 3),\n",
    "          include_top=False,\n",
    "          include_preprocessing=False,\n",
    "      )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    elif model_name == 'MobileNetV2':\n",
    "      base_model = keras.applications.MobileNetV2(\n",
    "          weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "          input_shape=(image_size[0], image_size[1], 3),\n",
    "          include_top=False,\n",
    "          alpha=1.0\n",
    "      )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    # Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create new model on top\n",
    "    inputs = keras.Input(shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "\n",
    "    # Pre-trained Xception weights requires that input be scaled\n",
    "    # from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "    # outputs: `(inputs * scale) + offset`\n",
    "    scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "    x = scale_layer(inputs)\n",
    "\n",
    "    # The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "    # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "    # base_model is running in inference mode here.\n",
    "    x = base_model(x, training=False)\n",
    "\n",
    "    top_layers = hp.Choice('Top layers', ['GlobalAveragePooling2D','FlattenAndDense','Flatten'])\n",
    "\n",
    "    if top_layers == 'GlobalAveragePooling2D':\n",
    "      x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "      x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "    elif top_layers == 'FlattenAndDense':\n",
    "      x = keras.layers.Flatten()(x)\n",
    "      x = keras.layers.Dense(\n",
    "          units=256,\n",
    "          activation='relu'\n",
    "      )(x)\n",
    "\n",
    "      x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "    elif top_layers == 'Flatten':\n",
    "      x = keras.layers.Flatten()(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(\n",
    "        units=8,\n",
    "        activation='softmax'\n",
    "    )(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.summary(show_trainable=True)\n",
    "\n",
    "    model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(), # optimizer,\n",
    "    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 4s 0us/step\n",
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " vgg19 (Functional)          (None, 4, 4, 512)         2002438   N          \n",
      "                                                       4                    \n",
      "                                                                            \n",
      " global_average_pooling2d (  (None, 512)               0         Y          \n",
      " GlobalAveragePooling2D)                                                    \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 512)               0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 8)                 4104      Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 20028488 (76.40 MB)\n",
      "Trainable params: 4104 (16.03 KB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "____________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x782585506fe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_4 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling_1 (Rescaling)     (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " vgg19 (Functional)          (None, 4, 4, 512)         2002438   N          \n",
      "                                                       4                    \n",
      "                                                                            \n",
      " global_average_pooling2d_1  (None, 512)               0         Y          \n",
      "  (GlobalAveragePooling2D)                                                  \n",
      "                                                                            \n",
      " dropout_1 (Dropout)         (None, 512)               0         Y          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 8)                 4104      Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 20028488 (76.40 MB)\n",
      "Trainable params: 4104 (16.03 KB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    max_trials=9,\n",
    "    executions_per_trial=1,\n",
    "    # Do not resume the previous search in the same directory.\n",
    "    overwrite=True,\n",
    "    objective=\"val_accuracy\",\n",
    "    # Set a directory to store the intermediate results.\n",
    "    directory=\"/tmp/phase_1-1\",\n",
    "    project_name=\"CRC classification\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 01m 31s]\n",
      "val_accuracy: 0.8979057669639587\n",
      "\n",
      "Best val_accuracy So Far: 0.9123036861419678\n",
      "Total elapsed time: 00h 17m 30s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=validation_ds,\n",
    "    # Use the TensorBoard callback.\n",
    "    # The logs will be write to \"/tmp/phase_1-1\".\n",
    "    callbacks=[keras.callbacks.TensorBoard(\"/tmp/phase_1-1\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! zip -r ./phase_1-1.zip /tmp/phase_1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir /tmp/phase_1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "Model (Choice)\n",
      "{'default': 'VGG19', 'conditions': [], 'values': ['VGG19', 'EfficientNetV2B0', 'MobileNetV2'], 'ordered': False}\n",
      "Top layers (Choice)\n",
      "{'default': 'GlobalAveragePooling2D', 'conditions': [], 'values': ['GlobalAveragePooling2D', 'FlattenAndDense', 'Flatten'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   N          \n",
      " nal)                                                                       \n",
      "                                                                            \n",
      " global_average_pooling2d (  (None, 1280)              0         Y          \n",
      " GlobalAveragePooling2D)                                                    \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 1280)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 8)                 10248     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 5929560 (22.62 MB)\n",
      "Trainable params: 10248 (40.03 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "____________________________________________________________________________\n",
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   N          \n",
      " nal)                                                                       \n",
      "                                                                            \n",
      " flatten (Flatten)           (None, 32000)             0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 256)               8192256   Y          \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 256)               0         Y          \n",
      "                                                                            \n",
      " dense_1 (Dense)             (None, 8)                 2056      Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 14113624 (53.84 MB)\n",
      "Trainable params: 8194312 (31.26 MB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "____________________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 10248     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5929560 (22.62 MB)\n",
      "Trainable params: 10248 (40.03 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in /tmp/phase_1-1/CRC classification\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "Model: EfficientNetV2B0\n",
      "Top layers: GlobalAveragePooling2D\n",
      "Score: 0.9123036861419678\n",
      "\n",
      "Trial 8 summary\n",
      "Hyperparameters:\n",
      "Model: EfficientNetV2B0\n",
      "Top layers: FlattenAndDense\n",
      "Score: 0.8979057669639587\n",
      "\n",
      "Trial 6 summary\n",
      "Hyperparameters:\n",
      "Model: MobileNetV2\n",
      "Top layers: FlattenAndDense\n",
      "Score: 0.8939790725708008\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "Model: EfficientNetV2B0\n",
      "Top layers: Flatten\n",
      "Score: 0.8913612365722656\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "Model: MobileNetV2\n",
      "Top layers: GlobalAveragePooling2D\n",
      "Score: 0.8848167657852173\n",
      "\n",
      "Trial 7 summary\n",
      "Hyperparameters:\n",
      "Model: MobileNetV2\n",
      "Top layers: Flatten\n",
      "Score: 0.8782722353935242\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "Model: VGG19\n",
      "Top layers: FlattenAndDense\n",
      "Score: 0.8704188466072083\n",
      "\n",
      "Trial 5 summary\n",
      "Hyperparameters:\n",
      "Model: VGG19\n",
      "Top layers: Flatten\n",
      "Score: 0.8612565398216248\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "Model: VGG19\n",
      "Top layers: GlobalAveragePooling2D\n",
      "Score: 0.8468586206436157\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    base_model = keras.applications.EfficientNetV2B0(\n",
    "        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=(image_size[0], image_size[1], 3),\n",
    "        include_top=False,\n",
    "        include_preprocessing=False,\n",
    "    )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    # Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create new model on top\n",
    "    inputs = keras.Input(shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "    # Pre-trained Xception weights requires that input be scaled\n",
    "    # from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "    # outputs: `(inputs * scale) + offset`\n",
    "    scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "    x = scale_layer(inputs)\n",
    "\n",
    "    # The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "    # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "    # base_model is running in inference mode here.\n",
    "    x = base_model(x, training=False)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "    outputs = keras.layers.Dense(\n",
    "        units=8,\n",
    "        activation='softmax',\n",
    "    )(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.summary(show_trainable=True)\n",
    "\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    optimizer_name = hp.Choice('optimizer', ['Adam','RMSprop', 'Adagrad', 'Nadam', 'NAG'])\n",
    "\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'Nadam':\n",
    "        optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'NAG':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=keras.losses.sparse_categorical_crossentropy,\n",
    "      metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "24274472/24274472 [==============================] - 2s 0us/step\n",
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   N          \n",
      " nal)                                                                       \n",
      "                                                                            \n",
      " global_average_pooling2d (  (None, 1280)              0         Y          \n",
      " GlobalAveragePooling2D)                                                    \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 1280)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 8)                 10248     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 5929560 (22.62 MB)\n",
      "Trainable params: 10248 (40.03 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='tuner_res',\n",
    "                     project_name='efficientnetv2-b0_phase1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 48s]\n",
      "val_accuracy: 0.8913612365722656\n",
      "\n",
      "Best val_accuracy So Far: 0.9070680737495422\n",
      "Total elapsed time: 00h 12m 29s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds, epochs=10, validation_data=validation_ds, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tuner_res/efficientnetv2-b0_phase1\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0016 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "optimizer: Nadam\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0014\n",
      "Score: 0.9070680737495422\n",
      "\n",
      "Trial 0017 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "optimizer: Adam\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0015\n",
      "Score: 0.9044502377510071\n",
      "\n",
      "Trial 0011 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "optimizer: Adam\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8939790725708008\n",
      "\n",
      "Trial 0019 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "optimizer: Nadam\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8913612365722656\n",
      "\n",
      "Trial 0014 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "optimizer: Nadam\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0001\n",
      "Score: 0.8900523781776428\n",
      "\n",
      "Trial 0015 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "optimizer: Adam\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0009\n",
      "Score: 0.8887434601783752\n",
      "\n",
      "Trial 0012 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "optimizer: Adam\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0011\n",
      "Score: 0.8848167657852173\n",
      "\n",
      "Trial 0013 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "optimizer: NAG\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0000\n",
      "Score: 0.8848167657852173\n",
      "\n",
      "Trial 0000 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "optimizer: NAG\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8795811533927917\n",
      "\n",
      "Trial 0001 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "optimizer: Nadam\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8743455410003662\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.001,\n",
       " 'optimizer': 'Nadam',\n",
       " 'tuner/epochs': 10,\n",
       " 'tuner/initial_epoch': 4,\n",
       " 'tuner/bracket': 2,\n",
       " 'tuner/round': 2,\n",
       " 'tuner/trial_id': '0014'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! zip -r ./efficientnetv2-b0_phase1.zip ./tuner_res/efficientnetv2-b0_phase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_8 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling_3 (Rescaling)     (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   N          \n",
      " nal)                                                                       \n",
      "                                                                            \n",
      " global_average_pooling2d_3  (None, 1280)              0         Y          \n",
      "  (GlobalAveragePooling2D)                                                  \n",
      "                                                                            \n",
      " dropout_3 (Dropout)         (None, 1280)              0         Y          \n",
      "                                                                            \n",
      " dense_3 (Dense)             (None, 8)                 10248     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 5929560 (22.62 MB)\n",
      "Trainable params: 10248 (40.03 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "____________________________________________________________________________\n",
      "Epoch 1/20\n",
      "110/110 [==============================] - 19s 81ms/step - loss: 1.0271 - accuracy: 0.6754 - val_loss: 0.5887 - val_accuracy: 0.8272\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 6s 49ms/step - loss: 0.5029 - accuracy: 0.8454 - val_loss: 0.4457 - val_accuracy: 0.8613\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 10s 85ms/step - loss: 0.4010 - accuracy: 0.8774 - val_loss: 0.3876 - val_accuracy: 0.8743\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 10s 82ms/step - loss: 0.3497 - accuracy: 0.8906 - val_loss: 0.3517 - val_accuracy: 0.8822\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 0.3116 - accuracy: 0.9011 - val_loss: 0.3287 - val_accuracy: 0.8848\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.2884 - accuracy: 0.9100 - val_loss: 0.3167 - val_accuracy: 0.8848\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.2677 - accuracy: 0.9151 - val_loss: 0.3036 - val_accuracy: 0.8927\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2555 - accuracy: 0.9163 - val_loss: 0.2932 - val_accuracy: 0.9031\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2399 - accuracy: 0.9246 - val_loss: 0.2853 - val_accuracy: 0.9031\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.2315 - accuracy: 0.9260 - val_loss: 0.2834 - val_accuracy: 0.9058\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 0.2185 - accuracy: 0.9286 - val_loss: 0.2777 - val_accuracy: 0.9018\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2134 - accuracy: 0.9306 - val_loss: 0.2729 - val_accuracy: 0.9084\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.2022 - accuracy: 0.9400 - val_loss: 0.2680 - val_accuracy: 0.9084\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 0.1965 - accuracy: 0.9423 - val_loss: 0.2651 - val_accuracy: 0.9084\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.1867 - accuracy: 0.9409 - val_loss: 0.2643 - val_accuracy: 0.9031\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 0.1812 - accuracy: 0.9440 - val_loss: 0.2575 - val_accuracy: 0.9110\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 6s 49ms/step - loss: 0.1776 - accuracy: 0.9451 - val_loss: 0.2551 - val_accuracy: 0.9097\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.1754 - accuracy: 0.9443 - val_loss: 0.2596 - val_accuracy: 0.9097\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1730 - accuracy: 0.9454 - val_loss: 0.2548 - val_accuracy: 0.9123\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.1672 - accuracy: 0.9454 - val_loss: 0.2576 - val_accuracy: 0.9110\n",
      "Best epoch: 19\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 20 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_ds, epochs=20, validation_data=validation_ds)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model again with the best params and number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "24274472/24274472 [==============================] - 0s 0us/step\n",
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   N          \n",
      " nal)                                                                       \n",
      "                                                                            \n",
      " global_average_pooling2d (  (None, 1280)              0         Y          \n",
      " GlobalAveragePooling2D)                                                    \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 1280)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 8)                 10248     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 5929560 (22.62 MB)\n",
      "Trainable params: 10248 (40.03 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "____________________________________________________________________________\n",
      "Fitting the top layer of the model\n",
      "Epoch 1/15\n",
      "110/110 [==============================] - 24s 89ms/step - loss: 0.9778 - accuracy: 0.6969 - val_loss: 0.5551 - val_accuracy: 0.8534\n",
      "Epoch 2/15\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4846 - accuracy: 0.8551 - val_loss: 0.4248 - val_accuracy: 0.8757\n",
      "Epoch 3/15\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.3938 - accuracy: 0.8717 - val_loss: 0.3738 - val_accuracy: 0.8678\n",
      "Epoch 4/15\n",
      "110/110 [==============================] - 9s 77ms/step - loss: 0.3409 - accuracy: 0.8969 - val_loss: 0.3452 - val_accuracy: 0.8783\n",
      "Epoch 5/15\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 0.3088 - accuracy: 0.8997 - val_loss: 0.3231 - val_accuracy: 0.8940\n",
      "Epoch 6/15\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2868 - accuracy: 0.9117 - val_loss: 0.3085 - val_accuracy: 0.8966\n",
      "Epoch 7/15\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.2684 - accuracy: 0.9151 - val_loss: 0.2987 - val_accuracy: 0.8940\n",
      "Epoch 8/15\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2483 - accuracy: 0.9214 - val_loss: 0.2895 - val_accuracy: 0.8992\n",
      "Epoch 9/15\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.2388 - accuracy: 0.9240 - val_loss: 0.2860 - val_accuracy: 0.9031\n",
      "Epoch 10/15\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.2260 - accuracy: 0.9289 - val_loss: 0.2824 - val_accuracy: 0.9071\n",
      "Epoch 11/15\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.2174 - accuracy: 0.9343 - val_loss: 0.2742 - val_accuracy: 0.9018\n",
      "Epoch 12/15\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.2085 - accuracy: 0.9354 - val_loss: 0.2739 - val_accuracy: 0.9058\n",
      "Epoch 13/15\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.2041 - accuracy: 0.9389 - val_loss: 0.2673 - val_accuracy: 0.9058\n",
      "Epoch 14/15\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.1921 - accuracy: 0.9403 - val_loss: 0.2696 - val_accuracy: 0.9045\n",
      "Epoch 15/15\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.1866 - accuracy: 0.9443 - val_loss: 0.2635 - val_accuracy: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7b463070b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = keras.applications.EfficientNetV2B0(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(image_size[0], image_size[1], 3),\n",
    "    include_top=False,\n",
    "    include_preprocessing=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(\n",
    "    units=8,\n",
    "    activation='softmax',\n",
    ")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=0.001),\n",
    "    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "print(\"Fitting the top layer of the model\")\n",
    "model.fit(train_ds, epochs=15, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 35ms/step - loss: 0.2331 - accuracy: 0.9266\n",
      "[test loss, test accuracy]: [0.23314984142780304, 0.926630437374115]\n"
     ]
    }
   ],
   "source": [
    "eval_result = model.evaluate(test_ds)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{os.environ['DRIVE_DATA_DIR']}/EfficientNetV2B0-Nadam-0.001.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   N          \n",
      " nal)                                                                       \n",
      "                                                                            \n",
      " global_average_pooling2d (  (None, 1280)              0         Y          \n",
      " GlobalAveragePooling2D)                                                    \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 1280)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 8)                 10248     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 5929560 (22.62 MB)\n",
      "Trainable params: 10248 (40.03 KB)\n",
      "Non-trainable params: 5919312 (22.58 MB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         Y          \n",
      "                                                                            \n",
      " efficientnetv2-b0 (Functio  (None, 5, 5, 1280)        5919312   Y          \n",
      " nal)                                                                       \n",
      "                                                                            \n",
      " global_average_pooling2d (  (None, 1280)              0         Y          \n",
      " GlobalAveragePooling2D)                                                    \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 1280)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 8)                 10248     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 5929560 (22.62 MB)\n",
      "Trainable params: 5868952 (22.39 MB)\n",
      "Non-trainable params: 60608 (236.75 KB)\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model_copy = keras.models.clone_model(model)\n",
    "    model_copy.set_weights(model.get_weights())\n",
    "\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-3, 5e-4, 1e-4])\n",
    "    optimizer_name = hp.Choice('optimizer', ['Adam','RMSprop', 'Adagrad', 'Nadam', 'NAG'])\n",
    "\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'Nadam':\n",
    "        optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'NAG':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model_copy.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=keras.losses.sparse_categorical_crossentropy,\n",
    "      metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='tuner_res',\n",
    "                     project_name='efficientnetv2-b0_phase2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 31s]\n",
      "val_accuracy: 0.9175392389297485\n",
      "\n",
      "Best val_accuracy So Far: 0.9201570749282837\n",
      "Total elapsed time: 00h 09m 09s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds, epochs=10, validation_data=validation_ds, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tuner_res/efficientnetv2-b0_phase2\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0017 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "optimizer: Nadam\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0014\n",
      "Score: 0.9201570749282837\n",
      "\n",
      "Trial 0007 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.9188481569290161\n",
      "\n",
      "Trial 0011 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0005\n",
      "optimizer: Adagrad\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.9188481569290161\n",
      "\n",
      "Trial 0016 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0012\n",
      "Score: 0.9188481569290161\n",
      "\n",
      "Trial 0018 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0005\n",
      "optimizer: NAG\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.9188481569290161\n",
      "\n",
      "Trial 0009 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "optimizer: Nadam\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.9175392389297485\n",
      "\n",
      "Trial 0012 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0007\n",
      "Score: 0.9175392389297485\n",
      "\n",
      "Trial 0014 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "optimizer: Nadam\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0009\n",
      "Score: 0.9175392389297485\n",
      "\n",
      "Trial 0019 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "optimizer: NAG\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.9175392389297485\n",
      "\n",
      "Trial 0003 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "optimizer: NAG\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.9162303805351257\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0001,\n",
       " 'optimizer': 'Nadam',\n",
       " 'tuner/epochs': 10,\n",
       " 'tuner/initial_epoch': 4,\n",
       " 'tuner/bracket': 2,\n",
       " 'tuner/round': 2,\n",
       " 'tuner/trial_id': '0014'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.0955 - accuracy: 0.9697 - val_loss: 0.2574 - val_accuracy: 0.9175\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0967 - accuracy: 0.9691 - val_loss: 0.2590 - val_accuracy: 0.9123\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0984 - accuracy: 0.9674 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.0988 - accuracy: 0.9680 - val_loss: 0.2556 - val_accuracy: 0.9175\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0944 - accuracy: 0.9714 - val_loss: 0.2570 - val_accuracy: 0.9162\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0879 - accuracy: 0.9743 - val_loss: 0.2568 - val_accuracy: 0.9162\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.0888 - accuracy: 0.9709 - val_loss: 0.2602 - val_accuracy: 0.9110\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.0889 - accuracy: 0.9740 - val_loss: 0.2679 - val_accuracy: 0.9162\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.0897 - accuracy: 0.9746 - val_loss: 0.2661 - val_accuracy: 0.9202\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 8s 65ms/step - loss: 0.0868 - accuracy: 0.9737 - val_loss: 0.2584 - val_accuracy: 0.9175\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0838 - accuracy: 0.9769 - val_loss: 0.2621 - val_accuracy: 0.9162\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0871 - accuracy: 0.9737 - val_loss: 0.2629 - val_accuracy: 0.9136\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.0835 - accuracy: 0.9760 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.0854 - accuracy: 0.9723 - val_loss: 0.2636 - val_accuracy: 0.9136\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0870 - accuracy: 0.9726 - val_loss: 0.2647 - val_accuracy: 0.9149\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0846 - accuracy: 0.9743 - val_loss: 0.2645 - val_accuracy: 0.9162\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0832 - accuracy: 0.9737 - val_loss: 0.2686 - val_accuracy: 0.9110\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0847 - accuracy: 0.9723 - val_loss: 0.2669 - val_accuracy: 0.9136\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.0838 - accuracy: 0.9706 - val_loss: 0.2675 - val_accuracy: 0.9110\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 7s 58ms/step - loss: 0.0809 - accuracy: 0.9749 - val_loss: 0.2655 - val_accuracy: 0.9123\n",
      "Best epoch: 9\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 20 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_ds, epochs=20, validation_data=validation_ds)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.0844 - accuracy: 0.9714 - val_loss: 0.2645 - val_accuracy: 0.9162\n",
      "Epoch 2/9\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.0823 - accuracy: 0.9749 - val_loss: 0.2721 - val_accuracy: 0.9084\n",
      "Epoch 3/9\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.0800 - accuracy: 0.9769 - val_loss: 0.2737 - val_accuracy: 0.9097\n",
      "Epoch 4/9\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.0786 - accuracy: 0.9751 - val_loss: 0.2696 - val_accuracy: 0.9097\n",
      "Epoch 5/9\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.0744 - accuracy: 0.9780 - val_loss: 0.2798 - val_accuracy: 0.9097\n",
      "Epoch 6/9\n",
      "110/110 [==============================] - 9s 79ms/step - loss: 0.0831 - accuracy: 0.9709 - val_loss: 0.2708 - val_accuracy: 0.9110\n",
      "Epoch 7/9\n",
      "110/110 [==============================] - 15s 135ms/step - loss: 0.0756 - accuracy: 0.9769 - val_loss: 0.2651 - val_accuracy: 0.9123\n",
      "Epoch 8/9\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0725 - accuracy: 0.9786 - val_loss: 0.2745 - val_accuracy: 0.9084\n",
      "Epoch 9/9\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.0772 - accuracy: 0.9769 - val_loss: 0.2784 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7b45401619f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(train_ds, epochs=best_epoch, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2150 - accuracy: 0.9253\n",
      "[test loss, test accuracy]: [0.21495695412158966, 0.92527174949646]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(test_ds)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
